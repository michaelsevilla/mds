# start 1 MON, 5 OSDs, 3 MDSs
sudo ../../cleanup.sh; sudo OSD=3 MDS=3 MON=1 ./vstart.sh -l -n; sudo ceph mds tell 0 injectargs '--debug-ms 0'; sudo ceph mds tell 1 injectargs '--debug-ms 0'; sudo ceph mds tell 2 injectargs '--debug-ms 0'

# mount /mnt/cephfs on 3 clients
mkdir /mnt/vol2/msevilla/ceph-logs/client
(sudo ceph-fuse /mnt/cephfs -d) > /mnt/vol2/msevilla/ceph-logs/client/client0 2>&1 &
(sudo ./ceph-fuse -c ceph.conf /mnt/cephfs -d) > /mnt/vol2/msevilla/ceph-logs/client/client0 2>&1 &
sudo chown -R msevilla:msevilla /mnt/cephfs

# start daemon to collect stats (right after heartbeat)
vim config.sh
./collect.sh
tailplot -s 3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,20,21,22,23,24,25,26,27,29,30,31 -f traverse_discover,traverse,dir_fetch,dir_commit,traverse_remote_ino,inodes_bottom,imported,imported_inodes,inodes_pin_tail,traverse_forward,inodes_top,traverse_dir_fetch,inodes_pinned,reply,traverse_hit,subtrees,caps,forward,exported,exported_inodes,dir_split,inodes_expired,traverse_lock,request,inodes_with_caps,q,inodes ceph/src/out/perf/mds-issdm-a.timing &
(removed inode_max, load_cent)

# run benchmark
/user/msevilla/programs/mdtest/mdtest -F -C -n 100000 -d /mnt/cephfs/dir0

# wait x seconds and force migration
sudo ceph mds tell 0 injectargs "--mds_force_migrate /dir0:2"

# stop MDS and delete fs
sudo ceph mds set_max_mds 0
sudo ceph mds fail {2,1,0}
sudo ceph fs rm sevilla_fs --yes-i-really-mean-it
sudo ceph osd pool delete cephfs_data cephfs_data --yes-i-really-really-mean-it
sudo ceph osd pool delete cephfs_metadata cephfs_metadata --yes-i-really-really-mean-it
ceph osd pool create cephfs_data 512
ceph osd pool create cephfs_metadata 512

# Make some graphs
# start 1 MON, 5 OSDs, 3 MDSs
sudo ../../cleanup.sh; sudo OSD=3 MDS=3 MON=1 ./vstart.sh -l -n; sudo ceph mds tell 0 injectargs '--debug-ms 0'; sudo ceph mds tell 1 injectargs '--debug-ms 0'; sudo ceph mds tell 2 injectargs '--debug-ms 0'

# mount /mnt/cephfs on 3 clients
mkdir /mnt/vol2/msevilla/ceph-logs/client
(sudo ceph-fuse /mnt/cephfs -d) > /mnt/vol2/msevilla/ceph-logs/client/client0 2>&1 &
(sudo ./ceph-fuse -c ceph.conf /mnt/cephfs -d) > /mnt/vol2/msevilla/ceph-logs/client/client0 2>&1 &
sudo chown -R msevilla:msevilla /mnt/cephfs

# start daemon to collect stats (right after heartbeat)
vim config.sh
./collect.sh
tailplot -s 3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,20,21,22,23,24,25,26,27,29,30,31 -f traverse_discover,traverse,dir_fetch,dir_commit,traverse_remote_ino,inodes_bottom,imported,imported_inodes,inodes_pin_tail,traverse_forward,inodes_top,traverse_dir_fetch,inodes_pinned,reply,traverse_hit,subtrees,caps,forward,exported,exported_inodes,dir_split,inodes_expired,traverse_lock,request,inodes_with_caps,q,inodes ceph/src/out/perf/mds-issdm-a.timing &

# run benchmark
/user/msevilla/programs/mdtest/mdtest -F -C -n 100000 -d /mnt/cephfs/dir0

# wait x seconds and force migration
sudo ceph -c ceph.conf mds tell 0 injectargs "--mds_force_migrate /dir0:2"


removed inode_max, load_cent 

# stop MDS and delete fs
sudo ceph mds set_max_mds 0
sudo ceph mds fail {2,1,0}
sudo ceph fs rm sevilla_fs --yes-i-really-mean-it
sudo ceph osd pool delete cephfs_data cephfs_data --yes-i-really-really-mean-it
sudo ceph osd pool delete cephfs_metadata cephfs_metadata --yes-i-really-really-mean-it
ceph osd pool create cephfs_data 512
ceph osd pool create cephfs_metadata 512




# Make some graphs
- 1MDS (issdm-15)
tailplot -s 3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,20,21,22,23,24,25,26,27,29,30,31 -f traverse_discover,traverse,dir_fetch,dir_commit,traverse_remote_ino,inodes_bottom,imported,imported_inodes,inodes_pin_tail,traverse_forward,inodes_top,traverse_dir_fetch,inodes_pinned,reply,traverse_hit,subtrees,caps,forward,exported,exported_inodes,dir_split,inodes_expired,traverse_lock,request,inodes_with_caps,q,inodes 1mds/perf/mds-issdm-15.timing -t "1MDS (issdm-15) Perf Counters" &
tailplot -s 3,5,6 -f user,sys,wait 1mds/cpu/issdm-15-20141027.tab -t "1MDS (issdm-15) CPU" &

- 2MDS (issdm-15)
tailplot -s 3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,20,21,22,23,24,25,26,27,29,30,31 -f traverse_discover,traverse,dir_fetch,dir_commit,traverse_remote_ino,inodes_bottom,imported,imported_inodes,inodes_pin_tail,traverse_forward,inodes_top,traverse_dir_fetch,inodes_pinned,reply,traverse_hit,subtrees,caps,forward,exported,exported_inodes,dir_split,inodes_expired,traverse_lock,request,inodes_with_caps,q,inodes 2mds/perf/mds-issdm-15.timing -t "2MDS (issdm-15) Perf Counters" &
tailplot -s 3,5,6 -f user,sys,wait 2mds/cpu/issdm-15-20141027.tab -t "2MDS (issdm-15) CPU" &

- 2MDS (issdm-41)
tailplot -s 3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,20,21,22,23,24,25,26,27,29,30,31 -f traverse_discover,traverse,dir_fetch,dir_commit,traverse_remote_ino,inodes_bottom,imported,imported_inodes,inodes_pin_tail,traverse_forward,inodes_top,traverse_dir_fetch,inodes_pinned,reply,traverse_hit,subtrees,caps,forward,exported,exported_inodes,dir_split,inodes_expired,traverse_lock,request,inodes_with_caps,q,inodes 2mds/perf/mds-issdm-41.timing -t "2MDS (issdm-41) Perf Counters" &
tailplot -s 3,5,6 -f user,sys,wait 2mds/cpu/issdm-41-20141027.tab -t "2MDS (issdm-41) CPU" &

- 3MDS (issdm-15)
tailplot -s 3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,20,21,22,23,24,25,26,27,29,30,31 -f traverse_discover,traverse,dir_fetch,dir_commit,traverse_remote_ino,inodes_bottom,imported,imported_inodes,inodes_pin_tail,traverse_forward,inodes_top,traverse_dir_fetch,inodes_pinned,reply,traverse_hit,subtrees,caps,forward,exported,exported_inodes,dir_split,inodes_expired,traverse_lock,request,inodes_with_caps,q,inodes 3mds/perf/mds-issdm-15.timing -t "1MDS (issdm-15) Perf Counters" &
tailplot -s 3,5,6 -f user,sys,wait 3mds/cpu/issdm-15-20141028.tab -t "3MDS (issdm-15) CPU" &

- 3MDS (issdm-41)
tailplot -s 3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,20,21,22,23,24,25,26,27,29,30,31 -f traverse_discover,traverse,dir_fetch,dir_commit,traverse_remote_ino,inodes_bottom,imported,imported_inodes,inodes_pin_tail,traverse_forward,inodes_top,traverse_dir_fetch,inodes_pinned,reply,traverse_hit,subtrees,caps,forward,exported,exported_inodes,dir_split,inodes_expired,traverse_lock,request,inodes_with_caps,q,inodes 3mds/perf/mds-issdm-41.timing -t "1MDS (issdm-41) Perf Counters" &
tailplot -s 3,5,6 -f user,sys,wait 3mds/cpu/issdm-41-20141028.tab -t "3MDS (issdm-41) CPU" &

- 3MDS (issdm-5)
tailplot -s 3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,20,21,22,23,24,25,26,27,29,30,31 -f traverse_discover,traverse,dir_fetch,dir_commit,traverse_remote_ino,inodes_bottom,imported,imported_inodes,inodes_pin_tail,traverse_forward,inodes_top,traverse_dir_fetch,inodes_pinned,reply,traverse_hit,subtrees,caps,forward,exported,exported_inodes,dir_split,inodes_expired,traverse_lock,request,inodes_with_caps,q,inodes 3mds/perf/mds-issdm-5.timing -t "1MDS (issdm-5) Perf Counters" &
tailplot -s 3,5,6 -f user,sys,wait 3mds/cpu/issdm-5-20141028.tab -t "3MDS (issdm-5) CPU" &


